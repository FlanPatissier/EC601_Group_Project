# EC601 - VQA - For Visually Impaired


**EC-601 Project 1** 
--------------------

Literature review of VQA. This includes researching data sets and different architectures used previously as well as the newest state of the art models. 
It also includes a detailed review of the different methods used depending on the type of problem that is being tackled. Visit [EC-601 HW1.pdf](https://github.com/mkhalil1998/EC601_Group_Project/blob/main/EC-601%20HW1.pdf) for more details. 

**VQA Sprint 1** 
-----------------

Defined our project user stories, as well as the evolution of research that has been done in VQA for visually impaired. A list of architectures has been chosen for us to begin looking into and training. Visit [VQA-Sprint1.pdf](https://github.com/mkhalil1998/EC601_Group_Project/blob/main/VQA-Sprint1.pdf) for more details. 

**VQA Sprint 2** 
-----------------

Were able to sucessfully train three models, one of which is the state of the art models and show the training and validation results. Also some testing was done to understand the flexibilities of the model being trained. Visit [VQA-Sprint2.pdf](https://github.com/mkhalil1998/EC601_Group_Project/blob/main/VQA-Sprint2.pdf) for more details. 

### Model 1: Visual Question Answering(https://arxiv.org/pdf/1505.00468.pdf).
  
  A pytorch implementation of the model was followed using [this github](https://github.com/tbmoon/basic_vqa). 
  
  Steps for the training and validation are found on the gitub listed above. 
  
  VQA - v2 data set is used for training and validation: https://visualqa.org/download.html.

  After training and validating on VQA - v2 we were able to get the following results: 
  
  ![alt text](https://github.com/mkhalil1998/EC601_Group_Project/blob/main/Images/train_val_basic_vqa.png)


**VQA Sprint 3** 
-----------------
Reformatted VizWiz data set to fit the structure of VQA v2 as well as reformatted VQA v2 data set to fit the structure of VizWiz. We then trained and validated the VizWiz data on one of our models. Finally, continued working on the state of the art model VinVL. Visit [VQA-Sprint3.pdf](https://github.com/mkhalil1998/EC601_Group_Project/blob/main/VQA-Sprint3.pdf) for more details. 

